{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INGEST LAMBDA - SCRAPES THE SITE\n",
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "raw_bucket = 'darrin-testing'\n",
    "\n",
    "def send_txt_to_s3(filename,data,bucket):\n",
    "    with open(filename,'w') as file:\n",
    "        file.write(str(data))\n",
    "    s3.Bucket(bucket).put_object(Key=filename,Body=open(filename,'rb'))\n",
    "    os.remove(filename)\n",
    "    return True\n",
    "\n",
    "manga_list = ['http://www.tenmanga.com/book/KINGDOM.html',\n",
    "              'http://www.tenmanga.com/book/Hardcore+Leveling+Warrior']\n",
    "\n",
    "for manga in manga_list:\n",
    "    r = requests.get(manga)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    # Add code to extract the manga name\n",
    "    manga_names = [soup.find_all('div',{'class': 'book-info'})[0].find('h1').text]\n",
    "    \n",
    "    # Add code to extract the raw list of chapters\n",
    "    chapter_list_raw = soup.find_all('ul',{'class': 'chapter-box'})\n",
    "    \n",
    "    # Send the raw chapter list and manga names to S3\n",
    "    manga = manga_names[0].replace(' ','_')\n",
    "    import_time = time.strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "    filename = '_'.join([manga,'info',import_time]) + '.txt'\n",
    "    data = manga_names + [str(chapter_list_raw[0])]\n",
    "    send_txt_to_s3(filename,data,raw_bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INITIAL PROCESSING LAMBDA - FOR NOW, DOES NOTHING BUT COPY\n",
    "# add code to copy the file from the raw bucket to the processed bucket\n",
    "# you can use this example: https://medium.com/@stephinmon.antony/aws-lambda-with-python-examples-2eb227f5fafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PROCESSING LAMBDA - PROCESSES INGESTED FILES\n",
    "import os\n",
    "import ast \n",
    "import time\n",
    "import json\n",
    "import boto3\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def send_dict_to_s3(filename,data,bucket):\n",
    "    import_time = time.strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "    with open(filename,'w') as outfile:\n",
    "        json.dump(data,outfile)\n",
    "    s3.Bucket(bucket).put_object(Key=filename,Body=open(filename,'rb'))\n",
    "    os.remove(filename)\n",
    "    return True\n",
    "\n",
    "def data_lengths_test(data):\n",
    "    if len(data['chapter']) == len(data['date_uploaded']) == len(data['url']):\n",
    "        return True\n",
    "    else:\n",
    "        raise ValueError('Data Column Lengths are not equal')\n",
    "\n",
    "# Connect to s3 buckets\n",
    "s3 = boto3.resource('s3',region_name='us-east-2')\n",
    "processed_bucket = 'darrin-testing'\n",
    "published_bucket = 'darrin-testing'\n",
    "\n",
    "# Download file that was just added\n",
    "filename_from_event = 'Hardcore_Leveling_Warrior_Manga_info_2019-03-24_09_53_47.txt'\n",
    "s3.Bucket(processed_bucket).download_file(filename_from_event,filename_from_event)\n",
    "\n",
    "# Read in data\n",
    "with open(filename_from_event,'r') as data:\n",
    "    data = ast.literal_eval(data.read())\n",
    "os.remove(filename_from_event)\n",
    "manga_name = data[0]\n",
    "chapter_list_raw = BeautifulSoup(data[1], 'html.parser')\n",
    "\n",
    "# Parse for chapter information\n",
    "chapter_links = []; chapter_names = []; date_uploads = [] \n",
    "for chapter in chapter_list_raw.find_all('li',{'class':None}):\n",
    "    chapter_links.append(chapter.find('div',{'class': 'chapter-name short'}).a.get('href'))\n",
    "    date_uploads.append(chapter.find('div',{'class': 'add-time page-hidden'}).text)\n",
    "    chapter_name_parts = chapter.find('div',{'class': 'chapter-name short'}).text.split(' ')\n",
    "    if chapter_name_parts[-1].strip()[-3:] == 'new':\n",
    "        chapter_names.append(chapter_name_parts[-1].strip()[:-3])\n",
    "    else:\n",
    "        chapter_names.append(chapter_name_parts[-1])\n",
    "\n",
    "# Create dict and send data\n",
    "data = {'title':manga_name,\n",
    "        'chapter':chapter_names, \n",
    "        'date_uploaded':date_uploads, \n",
    "        'url':chapter_links}\n",
    "\n",
    "# Run Unit Tests\n",
    "data_lengths_test(data)\n",
    "\n",
    "# It doesn't matter if the file extension is json or txt\n",
    "# - that just helps the machine know what to open it with\n",
    "filename = filename_from_event.replace('info','parsed')\n",
    "send_dict_to_s3(filename,data,published_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are chapters for this manga\n"
     ]
    }
   ],
   "source": [
    "# COMPARISON LAMBDA - ADD NEW LINES TO DYNAMODB TABLE\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import boto3\n",
    "from decimal import Decimal, InvalidOperation\n",
    "from boto3.dynamodb.conditions import Key\n",
    "\n",
    "def ix_to_remove(data,response):\n",
    "    new_chapter_list = data['chapter']\n",
    "    new_date_uploaded_list = data['date_uploaded']\n",
    "    new_url_list = data['url']\n",
    "    remove_ix = []\n",
    "    for item in response['Items']:\n",
    "        try:\n",
    "            remove_ix.append(new_chapter_list.index(str(item['chapter'])))\n",
    "        except ValueError:\n",
    "            # If can't find the item, it's new\n",
    "            pass\n",
    "    return remove_ix\n",
    "\n",
    "# Connect to processed data bucket\n",
    "s3 = boto3.resource('s3',region_name='us-east-2')\n",
    "published_bucket = 'darrin-testing'\n",
    "\n",
    "# Connect to DynamoDB table\n",
    "dynamodb = boto3.resource('dynamodb',region_name='us-east-1')\n",
    "table = dynamodb.Table('manga_chapters')\n",
    "\n",
    "# Download file that was just added and load data\n",
    "filename_from_event = 'Hardcore_Leveling_Warrior_Manga_parsed_2019-03-24_09_53_47.txt'\n",
    "s3.Bucket(published_bucket).download_file(filename_from_event,filename_from_event)\n",
    "with open(filename_from_event) as json_file:\n",
    "    data = json.load(json_file)\n",
    "os.remove(filename_from_event)\n",
    "    \n",
    "# Query the DynamoDB table for that title\n",
    "title = data['title']\n",
    "response = table.query(TableName='manga_chapters',\n",
    "                       KeyConditionExpression=Key('title').eq(title))\n",
    "\n",
    "# If no records at present, insert all records as new\n",
    "if response['Count'] == 0:\n",
    "    print('This is a whole new manga')\n",
    "    # Need to add all items\n",
    "    for i in range(len(data['chapter'])):\n",
    "        try:\n",
    "            table.put_item(\n",
    "                Item = {\n",
    "                    'chapter': Decimal(data['chapter'][i]),\n",
    "                    'date_ingested': time.strftime(\"%Y-%m-%d\"),\n",
    "                    'date_uploaded': data['date_uploaded'][i],\n",
    "                    'title': title,\n",
    "                    'url': data['url'][i]\n",
    "                }\n",
    "            )\n",
    "        except InvalidOperation:\n",
    "            print('{} not added.'.format(data['chapter'][i]))\n",
    "# If records exist, only insert new records\n",
    "else:\n",
    "    print('There are chapters for this manga')\n",
    "    # Need to compare chapter numbers\n",
    "    remove_ix = ix_to_remove(data,response)\n",
    "\n",
    "    for index in sorted(remove_ix,reverse=True):\n",
    "        for my_list in [data['chapter'],data['date_uploaded'],data['url']]:\n",
    "            del my_list[index]\n",
    "\n",
    "    for i in range(len(data['chapter'])):\n",
    "        try:\n",
    "            table.put_item(\n",
    "                Item = {\n",
    "                    'title': title,\n",
    "                    'chapter': Decimal(data['chapter'][i]),\n",
    "                    'date_ingested': time.strftime(\"%Y-%m-%d\"),\n",
    "                    'date_uploaded': data['date_uploaded'][i],\n",
    "                    'url': data['url'][i]\n",
    "                }\n",
    "            )        \n",
    "        except InvalidOperation:\n",
    "            print('{} not added.'.format(data['chapter'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
